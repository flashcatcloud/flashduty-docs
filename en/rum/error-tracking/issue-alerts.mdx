---
title: "Issue Alerts"
description: "Learn how RUM Issues trigger alerts"
---

RUM automatically aggregates all error events reported by the SDK into Issues, helping you prioritize and find the most impactful problems, making it easier to reduce service downtime and user frustration.

You can inspect aggregated Issues through daily checks in the console, or configure alert notifications for Issues to be notified immediately when problems occur.

## Enable Alerts

<Steps>
  <Step title="Enter Application Details">
    Go to "Application Details" - "Alert Settings" page
  </Step>
  <Step title="Enable Alerts">
    Turn on the alert switch and select multiple channels to deliver alerts to
  </Step>
  <Step title="Configure Notification Rules">
    Alert notification rules follow the escalation rules under the channel. You can set up responders for your team to assign alerts when they occur
  </Step>
</Steps>

<Frame>
  <img src="https://docs-cdn.flashcat.cloud/images/png/2bbd455a2ac702246e8399b6628f9158.png" alt="Alert Settings" />
</Frame>

<Warning>
You must have the On-call service enabled to turn on Issue alerts. Note that the On-call service is charged based on active users, but members without a License can also receive alert notifications - even the free version has basic notification capabilities.
</Warning>

## Alert Trigger Conditions

| Trigger Condition | Description |
|-------------------|-------------|
| **New Issue** | An error event causes a new Issue to appear, triggering an alert event |
| **Issue Update** | Error events continue to merge into an unclosed Issue (For Review, Reviewed), and more than 24 hours have passed since the last alert event was triggered, a new alert event will be triggered |
| **Issue Reopened** | A new error merges into a closed Issue, causing the Issue to be reopened, i.e., regression |

<Note>
- An Issue triggers an alert event, which is delivered to the channel
- Whether an alert notification is triggered depends on your integration configuration, noise reduction configuration, and escalation rule configuration under the channel
- When an Issue is closed, the system triggers a close-type alert event, and its associated incident may automatically recover
</Note>

## Alert Severity

The severity of alert events triggered by Issues is automatically determined by the system:

<Tabs>
  <Tab title="Basic Judgment">
    | Condition | Severity |
    |-----------|----------|
    | Issue has existed for more than 7 days | Info |
    | Crash issue | Critical |
  </Tab>
  <Tab title="Scoring System">
    Determine level through accumulated score:

    | Score Range | Severity |
    |-------------|----------|
    | ≥70 points | Critical |
    | ≥40 points | Warning |
    | &lt;40 points | Info |
  </Tab>
  <Tab title="Scoring Factors">
    | Factor | Scoring Rule |
    |--------|--------------|
    | **Environment Impact** | Production environment (50 points), Staging environment (30 points), Other environments (10 points) |
    | **Error Keywords** | Contains critical keywords (+30 points) or warning keywords (+15 points) |
    | **Suspected Cause** | API failure (+20 points), Code exception (+15 points), Unknown/Network error (+5 points) |
    | **Issue Duration** | Over 24 hours (+20 points), Over 12 hours (+10 points) |
  </Tab>
</Tabs>
